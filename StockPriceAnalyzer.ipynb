{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e78657b6-edd8-4896-a4f5-f14fe22d8a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b7fa0e9-78f2-4b5e-9d5a-9f9c56c1876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all files in the folde rcontaining all the stock sheets are saved in our neighbour folder into databases then merging all the dfs together into 1\n",
    "#the dataframes will stack on top of each other so that the number of columns remains when merging databases to each individual database\n",
    "\n",
    "#find the neighbour folder and saving all the files in said folder into a List called fileNames\n",
    "folder_path = './PythonData'\n",
    "fileNames = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "\n",
    "\n",
    "#creating an empty array to add all the databases to\n",
    "dfList=[]\n",
    "\n",
    "#convering each csv file to a database and then appending it into the dfList[] \n",
    "for i in range (0, len(fileNames)):\n",
    "    if os.path.isfile(fileNames[i]):\n",
    "        df = pd.read_csv(f'{fileNames[i]}') \n",
    "        ticker = fileNames[i].replace('.csv', '')#getting the ticker value from the array of file names\n",
    "        df['Ticker']=ticker#adding a ticker column with the rigasxdcv b,ht 'ticker' value for the file in the iteration\n",
    "    \n",
    "        dfList.append(df)\n",
    "\n",
    "#concatenating all the databases into one\n",
    "merged_df=pd.concat(dfList, ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e57a8d38-1226-4f55-85fa-ba2023db0e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty arrays to store the max, min prices and returns and other calculations for each stock sheet/ticker\n",
    "max_prices=[]\n",
    "max_returns=[]\n",
    "min_prices=[]\n",
    "min_returns=[]\n",
    "price_stds=[]\n",
    "return_stds=[]\n",
    "date_of_max_prices=[]\n",
    "percent_returns=[]\n",
    "log_returns=[]\n",
    "\n",
    "#creating a function to calculate percentage returns\n",
    "def PercentReturnCalculator (localReturn):\n",
    "    percentageReturn=localReturn*100\n",
    "    percentageReturnString=(str(percentageReturn)+\"%\")\n",
    "    return percentageReturnString\n",
    "\n",
    "#creating a function to calculate log returns\n",
    "def LogReturnCalculator (localReturn):\n",
    "    if (localReturn>-1):\n",
    "        logReturn=(np.log1p(localReturn))\n",
    "    else:\n",
    "        logReturn = \"the return value has to be greater than -1\"\n",
    "    return logReturn\n",
    "\n",
    "for e in range(0, len(fileNames)):#iterating through each file/stock sheet\n",
    "    returns=[]#creating an empty array to store all the return values in the file that is being iterated through\n",
    "    '''\n",
    "        creating a seperate dataframe out of the merged dataframe for each ticker/stock sheet by finding all the rows \n",
    "        that have the same value under the 'Ticker' column\n",
    "    '''\n",
    "    cutted_df = merged_df[merged_df['Ticker']==fileNames[e].replace('.csv', '')]\n",
    "    #appending the maximum and minimum prices in the cutted_df to the max_prices and min_prices arrays\n",
    "    maxValue=float(cutted_df['Adj Close'].max())\n",
    "    max_prices.append(maxValue)\n",
    "    min_prices.append(float(cutted_df['Adj Close'].min()))\n",
    "\n",
    "    singular_percent_returns = []\n",
    "    singular_log_returns = []\n",
    "    for a in range(0, len(cutted_df)-1):#iterating to calculate each return value in the cutted_df      \n",
    "        singular_return=(merged_df.iloc[a+1]['Adj Close']-merged_df.iloc[a]['Adj Close'])\n",
    "       \n",
    "        #calculating the percentage return for each return value and appending it into a temporary list\n",
    "        singular_percent_return = PercentReturnCalculator(singular_return)\n",
    "        singular_percent_returns.append(singular_percent_return) \n",
    "        \n",
    "        #doing the same thing for log returns as percentage returns above\n",
    "        singular_log_return = LogReturnCalculator(singular_return)\n",
    "        singular_log_returns.append(singular_log_return)\n",
    "\n",
    "        returns.append(singular_return)#appending each value to the empty array initialized at the start of the initial for loop   \n",
    "    \n",
    "    percent_returns.append(singular_percent_returns)#append the temporary list of percentage returns as a nested list inside [percent_returns]\n",
    "    log_returns.append(singular_log_returns)\n",
    "    \n",
    "    #appending the maximum and minimum return values and std values into their respective arrays\n",
    "    max_returns.append(float(max(returns)))\n",
    "    min_returns.append(float(min(returns)))\n",
    "    price_stds.append(cutted_df['Adj Close'].std())\n",
    "    return_stds.append(np.std(returns))\n",
    "    \n",
    "    #getting the value under the 'Date' column in the same row where 'Adj Close'==maxValue\n",
    "    date_of_max_prices.append(cutted_df.loc[cutted_df['Adj Close']==maxValue, 'Date'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb9cf9f7-6752-4d5b-a28e-2b3daa751b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new database to store all calculations where the arrays are columns\n",
    "values_db={\n",
    "    'maximum prices': max_prices,\n",
    "    'maximum returns': max_returns,\n",
    "    'minimum prices': min_prices,\n",
    "    'minimum returns': min_returns,\n",
    "    'standard deviation of all prices': price_stds,\n",
    "    'standard deviation of all returns': return_stds,\n",
    "    'date_of_max_prices': date_of_max_prices\n",
    "}\n",
    "\n",
    "#creating lists to store series objects of percentage and log returns from the elements in the nested lists\n",
    "percent_series_list=[]\n",
    "log_series_list=[]\n",
    "\n",
    "#iterating through each stock sheet to turn each element (all the returns for one stock sheet) in the nested lists into a series \n",
    "#appending those series' into the lists created above\n",
    "for i in range(0, len(fileNames)):\n",
    "    percent_series_list.append(pd.Series(percent_returns[i], name=f'{fileNames[i]}'))\n",
    "    log_series_list.append(pd.Series(log_returns[i], name=f'{fileNames[i]}'))\n",
    "\n",
    "#concatenating all series' into dataframes, the series are first stored into lists to allow for the columns in the dataframes to be different lengths\n",
    "percent_df=pd.concat(percent_series_list, axis=1)\n",
    "log_df=pd.concat(log_series_list, axis=1)\n",
    "\n",
    "Stock_Sheet_Analysis=pd.DataFrame(values_db, index =fileNames)\n",
    "\n",
    "#creating an excel file from the database created above\n",
    "with pd.ExcelWriter('Stock Sheet Data Calculations.xlsx') as writer:\n",
    "\n",
    "        Stock_Sheet_Analysis.to_excel(writer, sheet_name='Sheet 1')\n",
    "        percent_df.to_excel(writer, sheet_name='Percentage Returns')\n",
    "        log_df.to_excel(writer, sheet_name='Log Returns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ff7c36-f132-4299-a6ca-8ed9afa0ac86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
